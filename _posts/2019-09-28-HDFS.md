---
layout:     post
title:      "大数据系列（一）：HDFS文件系统"
subtitle:   "HDFS分布式文件系统架构"
date:       2019-09-28
author:     "ZihaoRao"
catalog: true
header-img: "img/in-post/bg/night-sky.jpg"
tags: 大数据
      Hadoop
      HDFS
---





### 总体概述
---
> This article is written in Chinese. If necessary, please consider using [Google Translate](http://translate.google.com/translate?hl=en&sl=auto&tl=en&u=https://steverao.github.io/2019/09/28/HDFS/)
>
> Hadoop在大数据领域有着举足轻重的地位，尽管随着技术的发展，其中的MapReduce计算框架似乎热度逐渐消减。但随着Hadoop生态圈的发展，其通过支持Spark，Storm和Hive等等十几种新计算引擎在其底层HDFS分布式文件系统上进行大数据处理，从而让Hadoop开始了第二个春天。作为Hadoop生态圈中最底层的基础设施，HDFS分布式文件系统为大数据的存储提供了有力的支持，本文亦是对其基础架构的一个介绍，另外本文所讨论技术点都是在Hadoop1.0版本范畴以内。                                                                                                                             



### 1.什么是HDFS？
---
&emsp;&emsp;什么是Hadoop Distributed File System(HDFS) 官网给出的解释如下：

> The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. HDFS relaxes a few POSIX requirements to enable streaming access to file system data. 

&emsp;&emsp;将上述官方介绍总结来看，简单来说，HDFS就是一个构建在**低成本硬件**上有**较强容错**能力的**分布式**文件系统。



### 2.为什么会出现HDFS？
---
&emsp;&emsp;首先对于这个问题，很显然其直接的原因得益于Google在2003年发表的《The Google File System》论文，随后，雅虎工程师Doug Cutting根据论文用Java语言复现出了HDFS（Hadoop Distributed File System）。

&emsp;&emsp;但透过现象，任何的技术发展都离不开现实的技术需求，对于像Google这样每时每刻都在产生大量数据的企业该如何有效存储这些大数据确实是一个在HDFS文件系统未问世前的难题。而HDFS则是解决搜索引擎相关场景**海量非结构化数据**（PB级），**一次写入多次读取**，**数据持续动态扩增**等难题的一种有效技术解决方案。




### 3.HDFS架构
---
&emsp;&emsp;一图胜千言，在介绍HDFS架构之间先看一下其架构图：

<div align="center"><img src="/img/in-post/content/hdfs/hdfs-architecture.gif" width="70%"/><b>HDFS架构图</b></div>



#### HDFS基本数据组织形式

&emsp;&emsp;HDFS是将数据以“块”的形式（上图绿色块）进行存储的，一个块默认大小为64MB，例如一个128MB的文件在HDFS中会被拆分成2个块进行存储。

#### HDFS组成模块

&emsp;&emsp;Master/Slave主从架构是分布式系统中常见的架构设计，作为分布式的文件系统，HDFS也采用了主从架构，上图中的Namenode就对应Master，而Datanode则是Slave。Namenode与Datanode之间以“心跳”形式保持联系。

##### Namenode

&emsp;&emsp;作为主节点，管理整个系统的资源分配与调度并负责与外部客户端交互。

&emsp;&emsp;其存储着文件的元数据如文件名，文件目录结构，文件属性（生成时间，副本数，文件权限），以及每个文件的块列表以及块所在的Datanode等等信息。

&emsp;&emsp;其周期性的接收来自Datanode的“心跳”信息从而掌控系统的实时状态。

##### Datanode

&emsp;&emsp;作为从节点，主要负责数据块的存储。

&emsp;&emsp;数据块在Datanode中以文件形式存储在其上的磁盘中，一个数据块包括两个文件，一个是数据本身，另一个则是元数据包括数据块的长度，块数据的校验和，以及时间戳等。

&emsp;&emsp;其周期性的向Namenode发送“心跳”信息，报告自己的健康程度。

##### Second Namenode

&emsp;&emsp;介绍Second Namenode之前首先要了解HDFS存储系统中机器宕机后数据恢复的策略。HDFS中有两个重要的文件用来预防系统硬件故障所引发的数据丢失。

- **fsimage文件：**其是内存命名空间元数据在外存的镜像文件。


- **editlog文件：**Namenode节点在内存中对所有元数据的操作在执行前都会先存储在editlog中，其作用类似于数据库中的日志文件，防止硬件故障时发生丢失修改。

&emsp;&emsp;在HDFS系统中，当正在执行任务的Active Namenode发生故障后，备份的Standby Namenode就会通过读取**fsimage**中的数据获得系统命名空间中元数据信息，再通过执行**editlog**中的操作完成因上一个Active Namenode宕机后系统所丢失的修改。

&emsp;&emsp;一般只有在这种启动新Active Namenode的时候才会去合并这两个文件，因此随着系统的持续运行，**editlog**中的数据越积越多，下一个Namenode启动所需时间也会越来越长，为了解决这一问题便出现了Second Namenode，它在系统运行过程中会周期的去合并上述两个文件，从而保证**editlog**中总是仅存储少量最新的修改操作，缩短了Namenode宕机后系统恢复所需的时长。



#### HDFS的问题解决之道

&emsp;&emsp;对于分布式文件系统，在其运行过程中以下三个问题无法避免。解决问题的好坏直接影响着系统的成败，我们来看看HDFS是如何对这三个问题给出解答的。

- **容错性**

  节点的宕机导致数据丢失是分布式系统中最常见的一类问题。HDFS通过多副本方式提高系统容错能力，其默认采用3副本策略，在兼顾可靠性与网络贷款的情况下，其最简单的副本放置策略如下：

  1.第一个副本放置在上传文件的Datanode中，如果是集群外提交，则随机挑选一台磁盘不太满，CPU不太忙的节点。

  2.第二个副本被放置在不同于第一个但随机选择的机架上。

  3.第三个副本被放置在与第二个副本相同的机架上。

  通过以上策略便可在数据冗余适当的情况下有效避免因各种软硬件故障导致的系统数据丢失问题。

- **速度**

  速度方面的优势源于 HDFS 合理的设计理念。HDFS 将一个文件分割成若干个块（Block），每个块分布在不同的机器中，每次操作一个文件的时候，实际上是多个机器在并发读取，这样无疑可进一步提高读取速度。

- **容量**

  在系统容量方面，HDFS理论上是可以无限制扩容，但实际上由于其元数据信息仅存储在一台 Namenode 中，所以它的大小还是会受到元数据存储空间的限制。不过在 Hadoop2.0 以后，在机器条件允许的情况下，一个 HDFS文件系统支撑起 PB 级别的存储还是绰绰有余。




### 4.HDFS工作流程
---
&emsp;&emsp;作为文件系统，其首要任务就是解决文件读取相关问题，所以从文件如何读取来了解HDFS的具体工作流程。

#### 文件的读取流程

<div align="center"><img src="/img/in-post/content/hdfs/hdfs-read.png" width="70%"/><b>HDFS读取文件</b></div>



1. 客户端通过调用FileSystem对象的open方法来读取希望打开的文件，该对象是分布式文件系统的一个实例。
2. 分布式文件系统实例FileSystem使用RPC来调用名称节点，以确定文件开头部分的块的位置，分布式系统实例返回一个FSDataInputStream对象给客户端进行数据读取。
3. FSDataInputStream根据选择最近数据节点上的块数据以流方式读取，数据从 Datanode 源源不断的流向客户端。当一个块读取完后，FSDataInputStream关闭与该数据节点的连接，读取下一个最近数据节点上的块数据。
4. 客户端完成读取，对文件系统数据输入流调用close方法。



#### 文件的写入流程

<div align="center"><img src="/img/in-post/content/hdfs/hdfs-read.png" width="70%"/><b>HDFS写入文件</b></div>



1. 客户端通过调用分布式系统FileSystem实例中的create方法来创建新文件。

2. 分布式系统FileSystem实例通过RPC去调用Namenode去创建一个没有 blocks 关联的新文件。如果创建成功，分布式文件系统返回一个文件系统数据输出流DFSOutputStream。

3. 客户端开始写数据到DFSOutputStream，DFSOutputStream将数据分成一个个的包，写入内部的数据队列data queue。

4. 客户端内部建立一个DataStreamer来处理数据队列，DataStreamer向名称节点要求分配一组存储数据的数据节点（默认为3），数据节点队列形成管道。DataStreamer将包发送给管道中第一个数据节点，该节点会存储包并且转发给管道中的第二个数据节点，第二个数据节点存储包并且转发给管道中第三个数据节点。

5. DataStreamer同时维护一个内部的等待包队列来等待数据节点的确认，称为确认队列，一个包只有在被管道中所有节点确认后才会被移出确认队列。

6. 客户端完成数据的写入后，就会在流中调用close方法，此方法会将余下的所有包放入数据节点管道并等待确认。

   ​

### 5.小结
---
- 本文从HDFS分布式文件系统的来由到其组织架构，再到其工作流程的这样顺序来对HDFS分布式文件系统背后的架构原理进行一个简单的介绍。既是希望让我也是让未学习过大数据技术或准备学习的读者对HDFS分布式文件系统有一个整体的认识，技术层面的细节不是本文的重点。

- 另外本文对于一些较为复杂的问题，如HDFS如何避免Namenode单点故障，系统的HA（High Availability）等等都介绍得不多，希望有兴趣的读者可以关注后续系列文章或者直接访问[官方文档特定章节](http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html)。

- 最后，HDFS分布式文件系统作为大数据领域的基础设施，为大数据的存取与运算提供了很好的支持。但对于小文件的读取和文件的反复修改等需求是不太擅长的，其架构特点已经为我们解答了。

  ​



### 参考资料
---
- 浙江大学软件学院贝毅君老师《大数据存储与处理》课程课件
- [Hadoop官方文档](http://hadoop.apache.org/)
- [Hadoop十年解读与发展预测，InfoQ](https://www.infoq.cn/article/hadoop-ten-years-interpretation-and-development-forecast)
- [大数据架构学习总结，王蒙](https://matt33.com/2018/07/15/hdfs-architecture-learn/)
- [大数据进击之路](https://data.cuteximi.com/ziyuan01/)

